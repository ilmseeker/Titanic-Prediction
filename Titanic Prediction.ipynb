{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis Libraries;\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "\n",
    "# Data Visualization Libraries;\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To Ignore Warnings;\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To Display All Columns:\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Model Selection\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler,minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data with pd.read_csv():\n",
    "\n",
    "train_data = pd.read_csv(\"c:/users/haider/desktop/wall/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"c:/users/haider/desktop/wall/titanic/test.csv\")\n",
    "\n",
    "# Copy data in order to avoid any change in the original:\n",
    "train = train_data.copy()\n",
    "test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of training dataset\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying 1st five rows of training dataset\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Count, Mean, Std Deviation and Minimum values of the training dataset and transposing the result\n",
    "\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of testing dataset\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying 1st five rows of testing dataset\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Count, Mean, Std Deviation and Minimum values of the testing dataset and transposing the result\n",
    "\n",
    "test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph to display the Non-null and Null counts in the dataset\n",
    "\n",
    "import missingno as msno\n",
    "msno.bar(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of categorical variables\n",
    "\n",
    "train['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "# Barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.\n",
    "\n",
    "sns.barplot(x = 'Pclass', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'SibSp', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Parch', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Deleting Unnecessary Variables\n",
    "\n",
    "\n",
    "# We can drop the Ticket feature since it is unlikely to have useful information\n",
    "\n",
    "train = train.drop(['Ticket'], axis = 1)\n",
    "test = test.drop(['Ticket'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe([0.10,0.25,0.50,0.75,0.90,0.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like there is a problem in Fare max data. Visualize with boxplot.\n",
    "sns.boxplot(x = train['Fare']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train['Fare'].quantile(0.25)\n",
    "Q3 = train['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_limit = Q1-1.5*IQR\n",
    "lower_limit\n",
    "\n",
    "upper_limit = Q3 + 1.5*IQR\n",
    "upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations with Fare data higher than the upper limit.\n",
    "\n",
    "train['Fare'] > (upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In boxplot, there are too many data higher than upper limit. Replacing the highest values.\n",
    "\n",
    "train['Fare'] = train['Fare'].replace(512.3292, 312)\n",
    "test['Fare'] = test['Fare'].replace(512.3292, 312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding and replacing Null values with '0' in the datsets\n",
    "\n",
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"].fillna(0, inplace = True)\n",
    "train[\"Cabin\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Age\"].fillna(0, inplace = True)\n",
    "test[\"Cabin\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing '0' in \"Age\" with the mean of \"Age\"\n",
    "\n",
    "train['Age'] = train['Age'].replace(0,(train['Age'].mean()))\n",
    "test['Age'] = test['Age'].replace(0,(test['Age'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with the most frequent value:\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Fare\"] = test[\"Fare\"].fillna(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CabinBool variable which states if someone has a Cabin data or not:\n",
    "\n",
    "train[\"CabinBool\"] = train[\"Cabin\"].isnull().astype('int')\n",
    "test[\"CabinBool\"] = test[\"Cabin\"].isnull().astype('int')\n",
    "\n",
    "train = train.drop(['Cabin'], axis = 1)\n",
    "test = test.drop(['Cabin'], axis = 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each Embarked value to a numerical value:\n",
    "\n",
    "embarked_mapping = {\"S\": 1, \"C\":2, \"Q\":3}\n",
    "\n",
    "train['Embarked'] = train['Embarked'].map(embarked_mapping)\n",
    "test['Embarked'] = test['Embarked'].map(embarked_mapping)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sex values into 1-0:\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "lbe = preprocessing.LabelEncoder()\n",
    "\n",
    "train[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\n",
    "test[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Title\"] = train[\"Name\"].str.extract('([A-Za-z]+)\\.', expand = False)\n",
    "test[\"Title\"] = test[\"Name\"].str.extract('([A-Za-z]+)\\.', expand = False)\n",
    "\n",
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady','Capt','Col','Don','Dr','Major','Rev','Jonkheer','Dona'], 'Rare')\n",
    "train['Title'] = train['Title'].replace(['Countess','Lady','Sir'], 'Royal')\n",
    "train['Title'] = train['Title'].replace('Mlle','Miss')\n",
    "train['Title'] = train['Title'].replace('Ms','Miss')\n",
    "train['Title'] = train['Title'].replace('Mme','Mrs')\n",
    "\n",
    "test['Title'] = test['Title'].replace(['Lady','Capt','Col','Don','Dr','Major','Rev','Jonkheer','Dona'], 'Rare')\n",
    "test['Title'] = test['Title'].replace(['Countess','Lady','Sir'], 'Royal')\n",
    "test['Title'] = test['Title'].replace('Mlle','Miss')\n",
    "test['Title'] = test['Title'].replace('Ms','Miss')\n",
    "test['Title'] = test['Title'].replace('Mme','Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Title','Survived']].groupby(['Title'], as_index = False).agg({\"count\",\"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each of the title groups to a numerical value\n",
    "\n",
    "title_mapping = {\"Mr\":1, \"Miss\":2, \"Mrs\":3, \"Master\":4, \"Royal\":5, \"Rare\":5}\n",
    "\n",
    "train['Title'] = train['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'] = test['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name'], axis = 1)\n",
    "test = test.drop(['Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\n",
    "mylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\n",
    "test['AgeGroup'] = pd.cut(test[\"Age\"], bins,labels = mylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each Age value to a numerical value:\n",
    "age_mapping = {'Baby':1, 'Child':2, 'Teenager':3, 'Student':4, 'Young Adult':5, 'Adult':6, 'Senior':7}\n",
    "train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n",
    "test ['AgeGroup'] = test['AgeGroup'].map(age_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Age feature for now, might change:\n",
    "train = train.drop(['Age'], axis = 1)\n",
    "test = test.drop(['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Fare values into groups of numerical values:\n",
    "train['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1,2,3,4])\n",
    "test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Fare values:\n",
    "train = train.drop(['Fare'], axis = 1)\n",
    "test = test.drop(['Fare'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\n",
    "test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature of family size:\n",
    "\n",
    "train['Single'] = train['FamilySize'].map(lambda s:1 if s == 1 else 0)\n",
    "train['SmallFam'] = train['FamilySize'].map(lambda s:1 if s == 2 else 0)\n",
    "train['MedFam'] = train['FamilySize'].map(lambda s:1 if 3 <= s <= 4 else 0)\n",
    "train['LargeFam'] = train['FamilySize'].map(lambda s:1 if s>=5 else 0)\n",
    "\n",
    "test['Single'] = test['FamilySize'].map(lambda s:1 if s == 1 else 0)\n",
    "test['SmallFam'] = test['FamilySize'].map(lambda s:1 if s == 2 else 0)\n",
    "test['MedFam'] = test['FamilySize'].map(lambda s:1 if 3 <= s <= 4 else 0)\n",
    "test['LargeFam'] = test['FamilySize'].map(lambda s:1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Title and Embarked into dummy variables:\n",
    "\n",
    "train = pd.get_dummies(train, columns = [\"Title\"])\n",
    "train = pd.get_dummies(train, columns = [\"Embarked\"], prefix = \"Em\")\n",
    "\n",
    "test = pd.get_dummies(test, columns = [\"Title\"])\n",
    "test = pd.get_dummies(test, columns = [\"Embarked\"], prefix = \"Em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(\"Pclass\")[\"Survived\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat categorical values for Pclass:\n",
    "\n",
    "train[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\n",
    "train = pd.get_dummies(train, columns = [\"Pclass\"], prefix = \"Pc\")\n",
    "\n",
    "test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\n",
    "test = pd.get_dummies(test, columns = [\"Pclass\"], prefix = \"Pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train = train.drop(['PassengerId','Survived'], axis = 1)\n",
    "Y_train = train[\"Survived\"]\n",
    "X_test  = test.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
